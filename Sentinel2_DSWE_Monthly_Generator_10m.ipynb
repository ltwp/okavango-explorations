{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db061fc4",
   "metadata": {},
   "source": [
    "# Sentinel-2 DSWE Monthly Generator\n",
    "This code employs Sentinel-2 remote sensing data (blue, green, red, NIR, SWIR1, and SWIR2) within the Dynamic Surface Water Extent (DSWE) algorithm to develop monthly water inundation extent maps for a given study area. The code first creates monthly composites from avaialable Sentinel-2 data, then applies the algorithm, exporting each product as an asset to Google Earth Engine.\n",
    "\n",
    "DSWE Methodology: Jones, J.W., 2019. Improved Automated Detection of Subpixel-Scale Inundation—Revised Dynamic Surface Water Extent (DSWE) Partial Surface Water Tests. Remote Sensing 11, 374. https://doi.org/10.3390/rs11040374\n",
    "\n",
    "Sentinel-2: European Space Agency (ESA). (2023). Sentinel-2 imagery. Copernicus Open Access Hub. Retrieved from https://scihub.copernicus.eu/\n",
    "\n",
    "Google Earth Engine: Gorelick, N., Hancher, M., Dixon, M., Ilyushchenko, S., Thau, D., Moore, R., 2017. Google Earth Engine: Planetary-scale geospatial analysis for everyone. Remote Sensing of Environment, Big Remotely Sensed Data: tools, applications and experiences 202, 18–27. https://doi.org/10.1016/j.rse.2017.06.031\n",
    "\n",
    "Author: James (Huck) Rees, PhD Student, UC Santa Barbara Geography\n",
    "\n",
    "Date: March 10th, 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f761340",
   "metadata": {},
   "source": [
    "## Import packages and initialize GEE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0d11b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "import geopandas as gpd\n",
    "import os\n",
    "import logging\n",
    "from datetime import datetime, timedelta\n",
    "import calendar\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "import numpy as np\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from scipy.signal import find_peaks, argrelextrema\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize\n",
    "ee.Initialize()\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc9acaf",
   "metadata": {},
   "source": [
    "## Initialize functions for generating monthly Sentinel-2 composites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a2312cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_roi(shapefile_path):\n",
    "    \"\"\"Load ROI from a shapefile and return as an EE Geometry.\"\"\"\n",
    "    gdf = gpd.read_file(shapefile_path)\n",
    "    return ee.Geometry.Polygon(gdf.unary_union.__geo_interface__[\"coordinates\"])\n",
    "\n",
    "\n",
    "def mask_clouds_sentinel(image):\n",
    "    \"\"\"Mask clouds using Sentinel-2 Scene Classification Layer (SCL) and AOT.\"\"\"\n",
    "    scl = image.select(\"SCL\")\n",
    "    aot = image.select(\"AOT\").multiply(0.001)\n",
    "\n",
    "    # Mask out cloud-related classes\n",
    "    cloud_free = scl.neq(3).And(scl.neq(8)).And(scl.neq(9)).And(scl.neq(10))\n",
    "    clean_image = image.updateMask(cloud_free).updateMask(aot.lt(0.3))\n",
    "\n",
    "    return clean_image\n",
    "\n",
    "def create_monthly_composite_with_gap_filling(year, month, roi, \n",
    "                                               max_expansion=2, \n",
    "                                               coverage_threshold=0.95):\n",
    "    \"\"\"\n",
    "    Creates monthly Sentinel-2 composite with iterative temporal expansion.\n",
    "    \n",
    "    If the base month has insufficient coverage (due to clouds/shadows), this function\n",
    "    iteratively expands the temporal window to ±1 month, then ±2 months, filling only\n",
    "    the gaps left by the previous attempt.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    year : int\n",
    "        Year for composite\n",
    "    month : int\n",
    "        Month for composite (1-12)\n",
    "    roi : ee.Geometry\n",
    "        Region of interest\n",
    "    max_expansion : int, optional (default=2)\n",
    "        Maximum temporal expansion in months (±N months)\n",
    "    coverage_threshold : float, optional (default=0.95)\n",
    "        Minimum required coverage (0.0 to 1.0)\n",
    "        0.95 = 95% of ROI must have valid pixels\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    tuple : (composite, qc_value, actual_coverage)\n",
    "        composite : ee.Image - Final median composite with all bands\n",
    "        qc_value : int - Expansion level used (0=base month only, 1=±1 month, 2=±2 months)\n",
    "        actual_coverage : float - Final coverage as fraction (0.0 to 1.0)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get date range for base month\n",
    "    start_date = datetime(year, month, 1)\n",
    "    last_day = calendar.monthrange(year, month)[1]\n",
    "    end_date = datetime(year, month, last_day)\n",
    "    \n",
    "    # Convert to GEE date strings\n",
    "    start_str = start_date.strftime('%Y-%m-%d')\n",
    "    end_str = end_date.strftime('%Y-%m-%d')\n",
    "    \n",
    "    # Step 1: Try base month composite\n",
    "    logging.info(f\"  Attempting base month composite ({year}-{month:02d})...\")\n",
    "    \n",
    "    collection = ee.ImageCollection(\"COPERNICUS/S2_SR_HARMONIZED\")\\\n",
    "        .filterBounds(roi)\\\n",
    "        .filterDate(start_str, end_str)\\\n",
    "        .map(mask_clouds_sentinel)\n",
    "    \n",
    "    # Check if we have any images\n",
    "    count = collection.size().getInfo()\n",
    "    if count == 0:\n",
    "        logging.warning(f\"  No Sentinel-2 images available for {year}-{month:02d}\")\n",
    "        # Return empty result\n",
    "        return None, -1, 0.0\n",
    "    \n",
    "    # Create base composite\n",
    "    base_composite = collection.median().clip(roi)\n",
    "    base_coverage = calculate_coverage(base_composite, roi)\n",
    "    \n",
    "    logging.info(f\"  Base month coverage: {base_coverage*100:.1f}%\")\n",
    "    \n",
    "    # If coverage is sufficient, return base composite with QC=0\n",
    "    if base_coverage >= coverage_threshold:\n",
    "        return base_composite, 0, base_coverage\n",
    "    \n",
    "    # Step 2: Iteratively expand temporal window\n",
    "    final_composite = base_composite\n",
    "    final_coverage = base_coverage\n",
    "    qc_value = 0\n",
    "    \n",
    "    for expansion in range(1, max_expansion + 1):\n",
    "        logging.info(f\"  Coverage insufficient. Expanding to ±{expansion} month(s)...\")\n",
    "        \n",
    "        # Calculate expanded date range\n",
    "        expanded_start = start_date - relativedelta(months=expansion)\n",
    "        expanded_end = end_date + relativedelta(months=expansion)\n",
    "        \n",
    "        expanded_start_str = expanded_start.strftime('%Y-%m-%d')\n",
    "        expanded_end_str = expanded_end.strftime('%Y-%m-%d')\n",
    "        \n",
    "        # Get expanded collection\n",
    "        expanded_collection = ee.ImageCollection(\"COPERNICUS/S2_SR_HARMONIZED\")\\\n",
    "            .filterBounds(roi)\\\n",
    "            .filterDate(expanded_start_str, expanded_end_str)\\\n",
    "            .map(mask_clouds_sentinel)\n",
    "        \n",
    "        expanded_count = expanded_collection.size().getInfo()\n",
    "        if expanded_count == 0:\n",
    "            logging.warning(f\"  No additional images in ±{expansion} month window\")\n",
    "            continue\n",
    "        \n",
    "        # Create composite from expanded window\n",
    "        expanded_composite = expanded_collection.median().clip(roi)\n",
    "        \n",
    "        # Create mask of pixels that still need filling\n",
    "        # (pixels that are masked in current composite)\n",
    "        gap_mask = final_composite.mask().Not()\n",
    "        \n",
    "        # Fill gaps: use expanded composite only where current composite has no data\n",
    "        final_composite = final_composite.unmask(expanded_composite)\n",
    "        \n",
    "        # Calculate new coverage\n",
    "        final_coverage = calculate_coverage(final_composite, roi)\n",
    "        qc_value = expansion\n",
    "        \n",
    "        logging.info(f\"  Coverage after ±{expansion} month expansion: {final_coverage*100:.1f}%\")\n",
    "        \n",
    "        # If we've reached threshold, stop\n",
    "        if final_coverage >= coverage_threshold:\n",
    "            break\n",
    "    \n",
    "    # Final check\n",
    "    if final_coverage < coverage_threshold:\n",
    "        logging.warning(f\"  Final coverage ({final_coverage*100:.1f}%) still below threshold \"\n",
    "                       f\"({coverage_threshold*100:.0f}%) after {max_expansion} month expansion\")\n",
    "    \n",
    "    return final_composite, qc_value, final_coverage\n",
    "\n",
    "def calculate_coverage(image, roi):\n",
    "    \"\"\"\n",
    "    Calculate the fraction of valid (non-masked) pixels in an image over a region.\n",
    "    \n",
    "    Uses a coarser scale and single band to avoid computation timeouts.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    image : ee.Image\n",
    "        Image to calculate coverage for\n",
    "    roi : ee.Geometry\n",
    "        Region of interest\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    float : Coverage fraction (0.0 to 1.0)\n",
    "        1.0 = 100% coverage (all pixels valid)\n",
    "        0.0 = 0% coverage (all pixels masked)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Select just one band to check coverage (Red band - B4)\n",
    "    # This is much faster than checking all bands\n",
    "    single_band = image.select('B4')\n",
    "    \n",
    "    # Create a binary mask: 1 where data exists, 0 where masked\n",
    "    valid_pixels = single_band.mask()\n",
    "    \n",
    "    # Count valid pixels at coarser scale to speed up computation\n",
    "    # 30m scale is sufficient for coverage estimation\n",
    "    valid_count = valid_pixels.reduceRegion(\n",
    "        reducer=ee.Reducer.sum(),\n",
    "        geometry=roi,\n",
    "        scale=30,  # Coarser scale for faster computation\n",
    "        maxPixels=1e13,\n",
    "        tileScale=4  # Helps with large computations\n",
    "    ).getInfo()\n",
    "    \n",
    "    # Count total pixels in ROI\n",
    "    total_pixels = ee.Image.constant(1).clip(roi).reduceRegion(\n",
    "        reducer=ee.Reducer.count(),\n",
    "        geometry=roi,\n",
    "        scale=30,  # Match the scale used above\n",
    "        maxPixels=1e13,\n",
    "        tileScale=4\n",
    "    ).getInfo()\n",
    "    \n",
    "    # Extract values\n",
    "    valid_pixel_count = valid_count.get('B4', 0)\n",
    "    total_pixel_count = total_pixels.get('constant', 0)\n",
    "    \n",
    "    # Calculate coverage\n",
    "    coverage = valid_pixel_count / total_pixel_count if total_pixel_count > 0 else 0.0\n",
    "    \n",
    "    return coverage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d565813c",
   "metadata": {},
   "source": [
    "## Initialize functions for water masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eaa0d212",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_bimodal_trough(histogram_data, band_name='SWIR1', smoothing_sigma=2):\n",
    "    \"\"\"\n",
    "    Find the trough (local minimum) between two peaks in a bimodal distribution.\n",
    "    \n",
    "    This implements the concept from Inman & Lyons (2020) of finding the natural \n",
    "    boundary between wet and dry pixels in the SWIR reflectance histogram. When \n",
    "    you plot SWIR values for a wetland image, you typically see two \"humps\" \n",
    "    (peaks): one for water/wet areas (low reflectance) and one for dry land \n",
    "    (high reflectance). The valley (trough) between these peaks represents the \n",
    "    natural separation point.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    histogram_data : dict\n",
    "        GEE histogram output with structure: \n",
    "        {'BandName': {'bucketMeans': [...], 'histogram': [...]}}\n",
    "    band_name : str\n",
    "        Name of the band ('SWIR1' or 'SWIR2')\n",
    "    smoothing_sigma : float\n",
    "        Gaussian smoothing parameter to reduce noise in the histogram\n",
    "        Higher values = smoother curve but may miss subtle features\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    float : The reflectance value at the trough (threshold)\n",
    "    dict : Diagnostic information about the distribution\n",
    "    \"\"\"\n",
    "    \n",
    "    # Extract histogram data\n",
    "    band_data = histogram_data[band_name]\n",
    "    means = np.array(band_data['bucketMeans'])  # Reflectance values (x-axis)\n",
    "    counts = np.array(band_data['histogram'])    # Pixel counts (y-axis)\n",
    "    \n",
    "    # Smooth the histogram to reduce noise\n",
    "    # Think of this like drawing a smooth curve through scattered points\n",
    "    counts_smooth = gaussian_filter1d(counts, sigma=smoothing_sigma)\n",
    "    \n",
    "    # Find peaks (the two \"humps\" in the histogram)\n",
    "    # prominence ensures we only find significant peaks, not small bumps\n",
    "    peaks, peak_properties = find_peaks(\n",
    "        counts_smooth, \n",
    "        prominence=np.max(counts_smooth) * 0.1  # Peak must be at least 10% of tallest peak\n",
    "    )\n",
    "    \n",
    "    # If we don't find two clear peaks, fall back to percentile method\n",
    "    if len(peaks) < 2:\n",
    "        # Use the 30th percentile as a conservative wet/dry boundary\n",
    "        cumsum = np.cumsum(counts)\n",
    "        total = cumsum[-1]\n",
    "        threshold_idx = np.where(cumsum >= total * 0.30)[0][0]\n",
    "        threshold = means[threshold_idx]\n",
    "        \n",
    "        diagnostics = {\n",
    "            'method': 'percentile_fallback',\n",
    "            'threshold': threshold,\n",
    "            'peaks_found': len(peaks),\n",
    "            'wet_mode': None,\n",
    "            'dry_mode': None,\n",
    "            'reason': 'Bimodal structure not clear - using 30th percentile'\n",
    "        }\n",
    "        \n",
    "        return threshold, diagnostics\n",
    "    \n",
    "    # Sort peaks by reflectance value (left to right on histogram)\n",
    "    peak_indices = peaks[np.argsort(means[peaks])]\n",
    "    \n",
    "    # The first peak (leftmost) = wet mode (low reflectance)\n",
    "    # The second peak (rightmost) = dry mode (high reflectance)\n",
    "    wet_peak_idx = peak_indices[0]\n",
    "    dry_peak_idx = peak_indices[1] if len(peak_indices) > 1 else peak_indices[0]\n",
    "    \n",
    "    # Find the lowest point (trough) between the two peaks\n",
    "    search_range = counts_smooth[wet_peak_idx:dry_peak_idx+1]\n",
    "    local_minima = argrelextrema(search_range, np.less)[0]\n",
    "    \n",
    "    if len(local_minima) > 0:\n",
    "        # Take the deepest minimum (lowest point in the valley)\n",
    "        trough_local_idx = local_minima[np.argmin(search_range[local_minima])]\n",
    "        trough_idx = wet_peak_idx + trough_local_idx\n",
    "        threshold = means[trough_idx]\n",
    "    else:\n",
    "        # Fallback: use midpoint between the two peaks\n",
    "        threshold = (means[wet_peak_idx] + means[dry_peak_idx]) / 2\n",
    "    \n",
    "    # Package diagnostic information\n",
    "    diagnostics = {\n",
    "        'method': 'bimodal_trough',\n",
    "        'threshold': threshold,\n",
    "        'wet_mode': means[wet_peak_idx],           # Reflectance of wet peak\n",
    "        'wet_mode_count': int(counts[wet_peak_idx]),  # Height of wet peak\n",
    "        'dry_mode': means[dry_peak_idx],           # Reflectance of dry peak\n",
    "        'dry_mode_count': int(counts[dry_peak_idx]),  # Height of dry peak\n",
    "        'peaks_found': len(peaks),\n",
    "        'trough_position': (threshold - means[wet_peak_idx]) / (means[dry_peak_idx] - means[wet_peak_idx])  # 0-1 scale\n",
    "    }\n",
    "    \n",
    "    return threshold, diagnostics\n",
    "\n",
    "def calculate_dynamic_swir2_threshold(image, roi, min_swir2=400, max_swir2=1500,\n",
    "                                       save_plot=True, output_dir=None, \n",
    "                                       year=None, month=None):\n",
    "    \"\"\"\n",
    "    Calculate dynamic SWIR2 threshold for a given image based on its histogram.\n",
    "    \n",
    "    This function analyzes the distribution of SWIR2 reflectance values across\n",
    "    your study area and finds the natural separation between wet and dry pixels.\n",
    "    The threshold is scene-specific and adapts to seasonal flooding conditions.\n",
    "    \n",
    "    This simplified version returns only SWIR2 threshold for use in Test 6\n",
    "    (vegetated inundation enhancement).\n",
    "    \n",
    "    ADAPTED FOR SENTINEL-2: Uses DN values from B12 band instead of reflectance.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    image : ee.Image\n",
    "        The Sentinel-2 composite image\n",
    "    roi : ee.Geometry\n",
    "        Region of interest (your study area boundary)\n",
    "    min_swir2, max_swir2 : float\n",
    "        Safety constraints on SWIR2 threshold (DN units)\n",
    "        Default range: 400 to 1500 DN\n",
    "    save_plot : bool, optional (default=True)\n",
    "        Whether to save histogram plot with threshold\n",
    "    output_dir : str, optional (default=None)\n",
    "        Directory to save plots. If None, saves to current directory\n",
    "    year : int, optional\n",
    "        Year for plot filename\n",
    "    month : int, optional\n",
    "        Month for plot filename\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    float : The calculated SWIR2 threshold value (DN units)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Extract SWIR2 band (B12 for Sentinel-2)\n",
    "    swir2 = image.select(['B12'])\n",
    "    \n",
    "    # Get histogram from Google Earth Engine\n",
    "    hist_dict = swir2.reduceRegion(\n",
    "        reducer=ee.Reducer.histogram(maxBuckets=100),\n",
    "        geometry=roi,\n",
    "        scale=10,\n",
    "        maxPixels=1e13\n",
    "    ).getInfo()\n",
    "    \n",
    "    # Prepare histogram data for analysis\n",
    "    swir2_hist = {'B12': hist_dict['B12']}\n",
    "    \n",
    "    # Find the trough (natural boundary) in histogram\n",
    "    swir2_threshold, swir2_diag = find_bimodal_trough(swir2_hist, 'B12')\n",
    "    \n",
    "    # Apply safety constraints to prevent unreasonable values\n",
    "    swir2_threshold_clipped = np.clip(swir2_threshold, min_swir2, max_swir2)\n",
    "    \n",
    "    # Create plot if requested\n",
    "    if save_plot:\n",
    "        import matplotlib.pyplot as plt\n",
    "        import os\n",
    "        \n",
    "        # Extract histogram data\n",
    "        means = np.array(hist_dict['B12']['bucketMeans'])\n",
    "        counts = np.array(hist_dict['B12']['histogram'])\n",
    "        \n",
    "        # Create figure\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.bar(means, counts, width=(means[1] - means[0]) * 0.8, \n",
    "                color='steelblue', alpha=0.7, edgecolor='black', linewidth=0.5)\n",
    "        \n",
    "        # Add threshold line\n",
    "        plt.axvline(swir2_threshold_clipped, color='red', linestyle='--', \n",
    "                   linewidth=2, label=f'Threshold = {swir2_threshold_clipped:.0f} DN')\n",
    "        \n",
    "        # Add wet and dry mode lines if available\n",
    "        if swir2_diag.get('wet_mode') is not None:\n",
    "            plt.axvline(swir2_diag['wet_mode'], color='blue', linestyle=':', \n",
    "                       linewidth=1.5, alpha=0.7, label=f'Wet Mode = {swir2_diag[\"wet_mode\"]:.0f} DN')\n",
    "        if swir2_diag.get('dry_mode') is not None:\n",
    "            plt.axvline(swir2_diag['dry_mode'], color='orange', linestyle=':', \n",
    "                       linewidth=1.5, alpha=0.7, label=f'Dry Mode = {swir2_diag[\"dry_mode\"]:.0f} DN')\n",
    "        \n",
    "        # Labels and title\n",
    "        plt.xlabel('SWIR2 DN Value (Band 12)', fontsize=12, fontweight='bold')\n",
    "        plt.ylabel('Pixel Count', fontsize=12, fontweight='bold')\n",
    "        \n",
    "        if year and month:\n",
    "            plt.title(f'SWIR2 Histogram with Dynamic Threshold (DN Units)\\n{year}-{month:02d}', \n",
    "                     fontsize=14, fontweight='bold')\n",
    "        else:\n",
    "            plt.title('SWIR2 Histogram with Dynamic Threshold (DN Units)', \n",
    "                     fontsize=14, fontweight='bold')\n",
    "        \n",
    "        plt.legend(loc='upper right', fontsize=10)\n",
    "        plt.grid(True, alpha=0.3, linestyle='--')\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Determine output directory\n",
    "        if output_dir is None:\n",
    "            output_dir = os.getcwd()\n",
    "        else:\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        # Create filename\n",
    "        if year and month:\n",
    "            base_filename = f'SWIR2_threshold_DN_{year}_{month:02d}'\n",
    "        else:\n",
    "            base_filename = 'SWIR2_threshold_DN'\n",
    "        \n",
    "        # Save as PNG and JPEG\n",
    "        png_path = os.path.join(output_dir, f'{base_filename}.png')\n",
    "        jpeg_path = os.path.join(output_dir, f'{base_filename}.jpeg')\n",
    "        \n",
    "        plt.savefig(png_path, dpi=300, bbox_inches='tight')\n",
    "        plt.savefig(jpeg_path, dpi=300, bbox_inches='tight', format='jpeg')\n",
    "        plt.close()\n",
    "        \n",
    "        print(f\"Plots saved:\")\n",
    "        print(f\"  PNG:  {png_path}\")\n",
    "        print(f\"  JPEG: {jpeg_path}\")\n",
    "    \n",
    "    return float(swir2_threshold_clipped)\n",
    "\n",
    "def morphological_filter(dswe_image, size_threshold=150, max_class_threshold=2, \n",
    "                         roi=None, return_diagnostics=True):\n",
    "    \"\"\"\n",
    "    Remove isolated blobs of low-confidence water classifications that are completely\n",
    "    surrounded by dry pixels. Preserves any blob containing high-confidence water pixels\n",
    "    (class > 2) regardless of size, ensuring the main floodplain \"megablob\" is retained.\n",
    "    \n",
    "    ADAPTED FOR SENTINEL-2: Uses scale=10m and adjusted parameters for equivalent area coverage.\n",
    "    \n",
    "    A blob is removed if:\n",
    "    1. It is smaller than size_threshold (in pixels), AND\n",
    "    2. All pixels in the blob are class 1 or 2 (max value <= max_class_threshold)\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    dswe_image : ee.Image\n",
    "        DSWE classification image (0=no water, 1=low, 2=partial, 3=moderate, 4=high)\n",
    "    size_threshold : int, optional (default=150)\n",
    "        Maximum blob size (in pixels) eligible for removal\n",
    "        At 10m resolution: 150 pixels = 1.5 hectares\n",
    "        Default maintains similar area threshold as Landsat version (~4.5 ha at 30m)\n",
    "    max_class_threshold : int, optional (default=2)\n",
    "        Maximum DSWE class value - blobs with ANY pixel > this are always preserved\n",
    "        Default of 2 means blobs containing class 3 or 4 are kept regardless of size\n",
    "    roi : ee.Geometry, optional (default=None)\n",
    "        Region of interest for diagnostic calculations\n",
    "        If None, diagnostics cannot be calculated\n",
    "    return_diagnostics : bool, optional (default=True)\n",
    "        Whether to return diagnostic information about filtering\n",
    "        Requires roi to be specified\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    ee.Image or tuple:\n",
    "        If return_diagnostics=False: filtered DSWE image\n",
    "        If return_diagnostics=True: (filtered_dswe, diagnostics_dict)\n",
    "        \n",
    "    Diagnostics dict contains:\n",
    "        - pixels_removed: int\n",
    "        - area_removed_km2: float\n",
    "        - class_1_pixels_removed: int\n",
    "        - class_2_pixels_removed: int\n",
    "        - class_3_pixels_removed: int (should be 0)\n",
    "        - class_4_pixels_removed: int (should be 0)\n",
    "        - size_threshold_used: int\n",
    "        - max_class_threshold_used: int\n",
    "        - percent_water_removed: float\n",
    "    \"\"\"\n",
    "    \n",
    "    # Step 1: Create binary mask of any water (classes 1-4)\n",
    "    water_mask = dswe_image.gt(0)\n",
    "    \n",
    "    # Step 2: Label connected components\n",
    "    # Use 8-connectivity (diagonal neighbors connect) to avoid fragmenting natural wetlands\n",
    "    # maxSize is the tile size for processing - must be <= 1024\n",
    "    labeled = water_mask.connectedComponents(\n",
    "        connectedness=ee.Kernel.square(1),  # 8-connectivity\n",
    "        maxSize=256  # Tile size for processing (not max blob size!)\n",
    "    )\n",
    "    \n",
    "    # Step 3: Add labels band to DSWE image for connected components reduction\n",
    "    # This is the KEY fix - must add labels to the image being reduced\n",
    "    dswe_with_labels = dswe_image.addBands(labeled.select('labels'))\n",
    "    \n",
    "    # Step 4: Calculate statistics for each blob\n",
    "    # reduceConnectedComponents maps the blob-level statistic back to every pixel in that blob\n",
    "    blob_max = dswe_with_labels.reduceConnectedComponents(\n",
    "        reducer=ee.Reducer.max(),\n",
    "        labelBand='labels'\n",
    "    )\n",
    "    \n",
    "    blob_count = dswe_with_labels.reduceConnectedComponents(\n",
    "        reducer=ee.Reducer.count(),\n",
    "        labelBand='labels'\n",
    "    )\n",
    "    \n",
    "    # Step 5: Create removal mask\n",
    "    # Identify pixels belonging to blobs that should be removed\n",
    "    # Note: Band name is 'DSWE' (uppercase) after reduceConnectedComponents\n",
    "    is_small = blob_count.select('DSWE').lte(size_threshold)\n",
    "    is_low_confidence = blob_max.select('DSWE').lte(max_class_threshold)\n",
    "    removal_mask = is_small.And(is_low_confidence)\n",
    "    \n",
    "    # Step 6: Apply filter\n",
    "    # Set pixels in removable blobs to 0 (no water)\n",
    "    # All other pixels remain unchanged\n",
    "    filtered_dswe = dswe_image.where(removal_mask, 0)\n",
    "    \n",
    "    # Step 7: Calculate diagnostics if requested\n",
    "    diagnostics = None\n",
    "    if return_diagnostics and roi is not None:\n",
    "        try:\n",
    "            # Count total pixels changed\n",
    "            changed_pixels = dswe_image.neq(filtered_dswe).And(dswe_image.mask())\n",
    "            \n",
    "            # Calculate statistics\n",
    "            original_stats = dswe_image.gt(0).reduceRegion(\n",
    "                reducer=ee.Reducer.sum(),\n",
    "                geometry=roi,\n",
    "                scale=10,  # Sentinel-2 resolution\n",
    "                maxPixels=1e13\n",
    "            ).getInfo()\n",
    "            \n",
    "            filtered_stats = filtered_dswe.gt(0).reduceRegion(\n",
    "                reducer=ee.Reducer.sum(),\n",
    "                geometry=roi,\n",
    "                scale=10,  # Sentinel-2 resolution\n",
    "                maxPixels=1e13\n",
    "            ).getInfo()\n",
    "            \n",
    "            original_water_pixels = original_stats.get('DSWE', 0)\n",
    "            filtered_water_pixels = filtered_stats.get('DSWE', 0)\n",
    "            pixels_removed = original_water_pixels - filtered_water_pixels\n",
    "            area_removed_km2 = pixels_removed * 0.0001  # 10m pixels = 0.0001 km²\n",
    "            \n",
    "            # Count pixels by original class that were removed\n",
    "            class_1_removed = dswe_image.eq(1).And(changed_pixels).reduceRegion(\n",
    "                reducer=ee.Reducer.sum(),\n",
    "                geometry=roi,\n",
    "                scale=10,\n",
    "                maxPixels=1e13\n",
    "            ).getInfo().get('DSWE', 0)\n",
    "            \n",
    "            class_2_removed = dswe_image.eq(2).And(changed_pixels).reduceRegion(\n",
    "                reducer=ee.Reducer.sum(),\n",
    "                geometry=roi,\n",
    "                scale=10,\n",
    "                maxPixels=1e13\n",
    "            ).getInfo().get('DSWE', 0)\n",
    "            \n",
    "            # These should always be zero if filter works correctly\n",
    "            class_3_removed = dswe_image.eq(3).And(changed_pixels).reduceRegion(\n",
    "                reducer=ee.Reducer.sum(),\n",
    "                geometry=roi,\n",
    "                scale=10,\n",
    "                maxPixels=1e13\n",
    "            ).getInfo().get('DSWE', 0)\n",
    "            \n",
    "            class_4_removed = dswe_image.eq(4).And(changed_pixels).reduceRegion(\n",
    "                reducer=ee.Reducer.sum(),\n",
    "                geometry=roi,\n",
    "                scale=10,\n",
    "                maxPixels=1e13\n",
    "            ).getInfo().get('DSWE', 0)\n",
    "            \n",
    "            diagnostics = {\n",
    "                'pixels_removed': int(pixels_removed) if pixels_removed else 0,\n",
    "                'area_removed_km2': round(area_removed_km2, 2) if area_removed_km2 else 0.0,\n",
    "                'class_1_pixels_removed': int(class_1_removed) if class_1_removed else 0,\n",
    "                'class_2_pixels_removed': int(class_2_removed) if class_2_removed else 0,\n",
    "                'class_3_pixels_removed': int(class_3_removed) if class_3_removed else 0,\n",
    "                'class_4_pixels_removed': int(class_4_removed) if class_4_removed else 0,\n",
    "                'size_threshold_used': size_threshold,\n",
    "                'max_class_threshold_used': max_class_threshold,\n",
    "                'percent_water_removed': round(100 * pixels_removed / original_water_pixels, 2) if original_water_pixels > 0 else 0.0\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            logging.warning(f\"Could not calculate diagnostics: {e}\")\n",
    "            diagnostics = {\n",
    "                'pixels_removed': 0,\n",
    "                'area_removed_km2': 0.0,\n",
    "                'class_1_pixels_removed': 0,\n",
    "                'class_2_pixels_removed': 0,\n",
    "                'class_3_pixels_removed': 0,\n",
    "                'class_4_pixels_removed': 0,\n",
    "                'size_threshold_used': size_threshold,\n",
    "                'max_class_threshold_used': max_class_threshold,\n",
    "                'percent_water_removed': 0.0,\n",
    "                'error': str(e)\n",
    "            }\n",
    "    \n",
    "    # Add metadata to filtered image\n",
    "    filtered_dswe = filtered_dswe.set({\n",
    "        'morphological_filter_applied': True,\n",
    "        'blob_size_threshold': size_threshold,\n",
    "        'blob_max_class_threshold': max_class_threshold,\n",
    "        'sensor': 'Sentinel-2',\n",
    "        'resolution_m': 10\n",
    "    })\n",
    "    \n",
    "    if return_diagnostics:\n",
    "        return filtered_dswe, diagnostics\n",
    "    else:\n",
    "        return filtered_dswe\n",
    "\n",
    "def apply_dswe(image):\n",
    "    \"\"\"Apply DSWE classification to a Sentinel-2 image.\"\"\"\n",
    "    blue = image.select('B2')\n",
    "    green = image.select('B3')\n",
    "    red = image.select('B4')\n",
    "    nir = image.select('B8')\n",
    "    swir1 = image.select('B11')\n",
    "    swir2 = image.select('B12')\n",
    "\n",
    "    mndwi = green.subtract(swir1).divide(green.add(swir1)).rename(\"MNDWI\")\n",
    "    ndvi = nir.subtract(red).divide(nir.add(red)).rename(\"NDVI\")\n",
    "    mbsrv = green.add(red).rename(\"MBSRV\")\n",
    "    mbsrn = nir.add(swir1).rename(\"MBSRN\")\n",
    "    awesh = blue.add(green.multiply(2.5)).subtract(mbsrn.multiply(1.5)).subtract(swir2.multiply(0.25)).rename(\"AWESH\")\n",
    "\n",
    "    t1 = mndwi.gt(0.124)\n",
    "    t2 = mbsrv.gt(mbsrn)\n",
    "    t3 = awesh.gt(0)\n",
    "    t4 = (mndwi.gt(-0.44)).And(swir1.lt(900)).And(nir.lt(1500)).And(ndvi.lt(0.7))\n",
    "    t5 = (mndwi.gt(-0.5)).And(green.lt(1000)).And(swir1.lt(3000)).And(swir2.lt(1000)).And(nir.lt(2500))\n",
    "\n",
    "    dswe = (t1.multiply(1)\n",
    "            .add(t2.multiply(10))\n",
    "            .add(t3.multiply(100))\n",
    "            .add(t4.multiply(1000))\n",
    "            .add(t5.multiply(10000)))\n",
    "\n",
    "    no_water = dswe.eq(0).Or(dswe.eq(1)).Or(dswe.eq(10)).Or(dswe.eq(100)).Or(dswe.eq(1000))\n",
    "    high_conf_water = dswe.eq(1111).Or(dswe.eq(10111)).Or(dswe.eq(11101)).Or(dswe.eq(11110)).Or(dswe.eq(11111))\n",
    "    moderate_conf_water = dswe.eq(111).Or(dswe.eq(1011)).Or(dswe.eq(1101)).Or(dswe.eq(1110))\\\n",
    "        .Or(dswe.eq(10011)).Or(dswe.eq(10101)).Or(dswe.eq(10110)).Or(dswe.eq(11001))\\\n",
    "        .Or(dswe.eq(11010)).Or(dswe.eq(11100))\n",
    "    potential_wetland = dswe.eq(11000)\n",
    "    low_conf_water = dswe.eq(11).Or(dswe.eq(101)).Or(dswe.eq(110))\\\n",
    "        .Or(dswe.eq(1001)).Or(dswe.eq(1010)).Or(dswe.eq(1100))\\\n",
    "        .Or(dswe.eq(10000)).Or(dswe.eq(10001)).Or(dswe.eq(10010)).Or(dswe.eq(10100))\n",
    "\n",
    "    dswe_final = (no_water.multiply(0)\n",
    "                  .add(high_conf_water.multiply(4))\n",
    "                  .add(moderate_conf_water.multiply(3))\n",
    "                  .add(potential_wetland.multiply(2))\n",
    "                  .add(low_conf_water.multiply(1))\n",
    "                  .rename(\"DSWE\"))\n",
    "\n",
    "    return dswe_final\n",
    "\n",
    "def Dswe_with_Test6(image, roi, min_swir2=400, max_swir2=1500, \n",
    "                     save_plot=True, output_dir=None, year=None, month=None):\n",
    "    \"\"\"\n",
    "    Calculate DSWE classification with Test 6 enhancement for vegetated inundation.\n",
    "    \n",
    "    This function applies the standard DSWE algorithm, then upgrades class confidence\n",
    "    for pixels that also pass Test 6 (SWIR2 < dynamic threshold). This enhancement\n",
    "    is designed to better capture water beneath dense vegetation (e.g., papyrus swamps)\n",
    "    where traditional spectral indices may fail but SWIR2 still indicates moisture.\n",
    "    \n",
    "    ADAPTED FOR SENTINEL-2: Uses DN values from B12 band instead of reflectance.\n",
    "    \n",
    "    Upgrade logic:\n",
    "    - Class 0 (No Water) + Test 6 pass → Class 1 (Low Water)\n",
    "    - Class 1 (Low Water) + Test 6 pass → Class 2 (Partial Wetland)\n",
    "    - Class 2 (Partial Wetland) + Test 6 pass → Class 3 (Moderate Water)\n",
    "    - Class 3 (Moderate Water) + Test 6 pass → Class 4 (High Water)\n",
    "    - Class 4 (High Water) → Remains Class 4 (no change)\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    image : ee.Image\n",
    "        Sentinel-2 composite with standard bands\n",
    "    roi : ee.Geometry\n",
    "        Region of interest for threshold calculation\n",
    "    min_swir2, max_swir2 : float\n",
    "        Safety constraints on SWIR2 threshold (DN units)\n",
    "        Default range: 400 to 1500 DN\n",
    "    save_plot : bool, optional (default=True)\n",
    "        Whether to save SWIR2 histogram plot\n",
    "    output_dir : str, optional (default=None)\n",
    "        Directory to save plots\n",
    "    year : int, optional\n",
    "        Year for metadata and plot filename\n",
    "    month : int, optional\n",
    "        Month for metadata and plot filename\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    tuple : (upgraded_classification, original_classification, swir2_threshold)\n",
    "        - upgraded_classification: ee.Image with Test 6 upgrades applied\n",
    "        - original_classification: ee.Image with standard DSWE (for comparison)\n",
    "        - swir2_threshold: float, the calculated SWIR2 threshold value (DN)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Step 1: Run standard DSWE algorithm (using Sentinel-2 version)\n",
    "    original_dswe = apply_dswe(image)\n",
    "    \n",
    "    # Step 2: Calculate dynamic SWIR2 threshold\n",
    "    swir2_threshold = calculate_dynamic_swir2_threshold(\n",
    "        image, roi, \n",
    "        min_swir2=min_swir2, \n",
    "        max_swir2=max_swir2,\n",
    "        save_plot=save_plot,\n",
    "        output_dir=output_dir,\n",
    "        year=year,\n",
    "        month=month\n",
    "    )\n",
    "    \n",
    "    # Step 3: Create Test 6 (SWIR2 < threshold)\n",
    "    swir2 = image.select(['B12'])\n",
    "    test6 = swir2.lt(swir2_threshold)\n",
    "    \n",
    "    # Step 4: Apply upgrade logic\n",
    "    # Start with original classification\n",
    "    upgraded_dswe = original_dswe\n",
    "    \n",
    "    # Upgrade class 0 → 1 if Test 6 passes\n",
    "    upgraded_dswe = upgraded_dswe.where(\n",
    "        original_dswe.eq(0).And(test6), \n",
    "        1\n",
    "    )\n",
    "    \n",
    "    # Upgrade class 1 → 2 if Test 6 passes\n",
    "    upgraded_dswe = upgraded_dswe.where(\n",
    "        original_dswe.eq(1).And(test6), \n",
    "        2\n",
    "    )\n",
    "    \n",
    "    # Upgrade class 2 → 3 if Test 6 passes\n",
    "    upgraded_dswe = upgraded_dswe.where(\n",
    "        original_dswe.eq(2).And(test6), \n",
    "        3\n",
    "    )\n",
    "    \n",
    "    # Upgrade class 3 → 4 if Test 6 passes\n",
    "    upgraded_dswe = upgraded_dswe.where(\n",
    "        original_dswe.eq(3).And(test6), \n",
    "        4\n",
    "    )\n",
    "    \n",
    "    # Class 4 remains unchanged (no .where() operation needed)\n",
    "    \n",
    "    # Step 5: Add metadata to both images\n",
    "    metadata = {\n",
    "        'swir2_threshold_DN': swir2_threshold,\n",
    "        'test6_applied': True,\n",
    "        'algorithm': 'DSWE_with_Test6_Sentinel2',\n",
    "        'sensor': 'Sentinel-2',\n",
    "        'resolution_m': 10\n",
    "    }\n",
    "    \n",
    "    if year is not None:\n",
    "        metadata['year'] = year\n",
    "    if month is not None:\n",
    "        metadata['month'] = month\n",
    "    \n",
    "    upgraded_dswe = upgraded_dswe.set(metadata).rename(['DSWE'])\n",
    "    original_dswe = original_dswe.set({\n",
    "        'swir2_threshold_DN': swir2_threshold,\n",
    "        'test6_applied': False,\n",
    "        'algorithm': 'DSWE_standard_Sentinel2',\n",
    "        'sensor': 'Sentinel-2',\n",
    "        'resolution_m': 10\n",
    "    }).rename(['DSWE'])\n",
    "    \n",
    "    return upgraded_dswe, original_dswe, swir2_threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ba343d",
   "metadata": {},
   "source": [
    "## Implement functions for exporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "feec29d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_to_asset(image, year, month, asset_folder, roi, \n",
    "                    swir2_threshold=None, qc_value=None, \n",
    "                    morpho_diagnostics=None, size_threshold=150, \n",
    "                    max_class_threshold=2):\n",
    "    \"\"\"\n",
    "    Export DSWE composite to GEE asset with comprehensive metadata.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    image : ee.Image\n",
    "        DSWE classification image to export\n",
    "    year : int\n",
    "        Year of the data\n",
    "    month : int\n",
    "        Month of the data (1-12)\n",
    "    asset_folder : str\n",
    "        GEE asset folder path\n",
    "    roi : ee.Geometry\n",
    "        Region of interest for export\n",
    "    swir2_threshold : float, optional\n",
    "        SWIR2 threshold value (DN) used in Test 6\n",
    "    qc_value : int, optional\n",
    "        Quality control value (0=base month, 1=±1 month, 2=±2 months)\n",
    "    morpho_diagnostics : dict, optional\n",
    "        Dictionary containing morphological filter diagnostics\n",
    "    size_threshold : int, optional (default=150)\n",
    "        Blob size threshold used in morphological filter\n",
    "    max_class_threshold : int, optional (default=2)\n",
    "        Max class threshold used in morphological filter\n",
    "    \"\"\"\n",
    "    \n",
    "    asset_id = f\"{asset_folder}/DSWE_{year}_{month:02d}\"\n",
    "    \n",
    "    # Check if asset already exists\n",
    "    try:\n",
    "        ee.data.getAsset(asset_id)\n",
    "        logging.info(f\"Skipping {asset_id}, already exists.\")\n",
    "        return\n",
    "    except:\n",
    "        pass  # Asset doesn't exist, continue with export\n",
    "    \n",
    "    # Build comprehensive metadata dictionary\n",
    "    metadata = {\n",
    "        'year': year,\n",
    "        'month': month,\n",
    "        'algorithm': 'DSWE_with_Test6_Sentinel2',\n",
    "        'sensor': 'Sentinel-2',\n",
    "        'resolution_m': 10,\n",
    "        'test6_applied': True if swir2_threshold is not None else False,\n",
    "        'morphological_filter_applied': True if morpho_diagnostics is not None else False,\n",
    "        'processing_date': datetime.now().isoformat()\n",
    "    }\n",
    "    \n",
    "    # Add SWIR2 threshold if provided\n",
    "    if swir2_threshold is not None:\n",
    "        metadata['swir2_threshold_DN'] = float(swir2_threshold)\n",
    "    \n",
    "    # Add QC value if provided\n",
    "    if qc_value is not None:\n",
    "        metadata['qc_temporal_expansion'] = int(qc_value)\n",
    "        metadata['qc_description'] = f\"0=base month, 1=±1 month, 2=±2 months (value={qc_value})\"\n",
    "    \n",
    "    # Add morphological filter parameters\n",
    "    metadata['blob_size_threshold'] = int(size_threshold)\n",
    "    metadata['blob_max_class_threshold'] = int(max_class_threshold)\n",
    "    \n",
    "    # Add morphological filter diagnostics if provided\n",
    "    if morpho_diagnostics is not None:\n",
    "        metadata['pixels_removed'] = int(morpho_diagnostics.get('pixels_removed', 0))\n",
    "        metadata['area_removed_km2'] = float(morpho_diagnostics.get('area_removed_km2', 0.0))\n",
    "        metadata['class_1_pixels_removed'] = int(morpho_diagnostics.get('class_1_pixels_removed', 0))\n",
    "        metadata['class_2_pixels_removed'] = int(morpho_diagnostics.get('class_2_pixels_removed', 0))\n",
    "        metadata['class_3_pixels_removed'] = int(morpho_diagnostics.get('class_3_pixels_removed', 0))\n",
    "        metadata['class_4_pixels_removed'] = int(morpho_diagnostics.get('class_4_pixels_removed', 0))\n",
    "        metadata['percent_water_removed'] = float(morpho_diagnostics.get('percent_water_removed', 0.0))\n",
    "    \n",
    "    # Set metadata on image\n",
    "    image_with_metadata = image.set(metadata)\n",
    "    \n",
    "    # Export to asset\n",
    "    task = ee.batch.Export.image.toAsset(\n",
    "        image=image_with_metadata.select([\"DSWE\"]),\n",
    "        description=f\"DSWE_{year}_{month:02d}\",\n",
    "        assetId=asset_id,\n",
    "        scale=10,\n",
    "        region=roi,\n",
    "        maxPixels=1e13\n",
    "    )\n",
    "    task.start()\n",
    "    logging.info(f\"Exporting {asset_id}...\")\n",
    "    \n",
    "def export_qc_raster(qc_image, year, month, asset_folder, roi):\n",
    "    \"\"\"\n",
    "    Export quality control raster showing temporal expansion used.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    qc_image : ee.Image\n",
    "        QC raster with values 0, 1, or 2\n",
    "    year : int\n",
    "        Year of the data\n",
    "    month : int\n",
    "        Month of the data (1-12)\n",
    "    asset_folder : str\n",
    "        GEE asset folder path for QC products\n",
    "    roi : ee.Geometry\n",
    "        Region of interest for export\n",
    "    \"\"\"\n",
    "    \n",
    "    asset_id = f\"{asset_folder}/QC_{year}_{month:02d}\"\n",
    "    \n",
    "    # Check if asset already exists\n",
    "    try:\n",
    "        ee.data.getAsset(asset_id)\n",
    "        logging.info(f\"Skipping {asset_id}, already exists.\")\n",
    "        return\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # Add metadata\n",
    "    qc_with_metadata = qc_image.set({\n",
    "        'year': year,\n",
    "        'month': month,\n",
    "        'product_type': 'Quality_Control',\n",
    "        'description': 'Temporal expansion used: 0=base month, 1=±1 month, 2=±2 months',\n",
    "        'sensor': 'Sentinel-2',\n",
    "        'processing_date': datetime.now().isoformat()\n",
    "    })\n",
    "    \n",
    "    # Export\n",
    "    task = ee.batch.Export.image.toAsset(\n",
    "        image=qc_with_metadata,\n",
    "        description=f\"QC_{year}_{month:02d}\",\n",
    "        assetId=asset_id,\n",
    "        scale=10,\n",
    "        region=roi,\n",
    "        maxPixels=1e13\n",
    "    )\n",
    "    task.start()\n",
    "    logging.info(f\"Exporting {asset_id}...\")\n",
    "    \n",
    "def export_composite_image(image, year, month, composite_folder, roi, qc_value=None):\n",
    "    \"\"\"\n",
    "    Export the median composite image (RGB bands only) to GEE asset.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    image : ee.Image\n",
    "        Sentinel-2 composite image\n",
    "    year : int\n",
    "        Year of the data\n",
    "    month : int\n",
    "        Month of the data (1-12)\n",
    "    composite_folder : str\n",
    "        GEE asset folder path for composites\n",
    "    roi : ee.Geometry\n",
    "        Region of interest for export\n",
    "    qc_value : int, optional\n",
    "        Quality control value indicating temporal expansion used\n",
    "    \"\"\"\n",
    "    \n",
    "    asset_id = f\"{composite_folder}/Composite_{year}_{month:02d}\"\n",
    "    \n",
    "    # Check if asset already exists\n",
    "    try:\n",
    "        ee.data.getAsset(asset_id)\n",
    "        logging.info(f\"Skipping {asset_id}, already exists.\")\n",
    "        return\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # Select RGB bands (Red, Green, Blue)\n",
    "    rgb_image = image.select(['B4', 'B3', 'B2'])\n",
    "    \n",
    "    # Build metadata\n",
    "    metadata = {\n",
    "        'year': year,\n",
    "        'month': month,\n",
    "        'product_type': 'RGB_Composite',\n",
    "        'bands': 'B4,B3,B2 (Red,Green,Blue)',\n",
    "        'sensor': 'Sentinel-2',\n",
    "        'resolution_m': 10,\n",
    "        'processing_date': datetime.now().isoformat()\n",
    "    }\n",
    "    \n",
    "    # Add QC value if provided\n",
    "    if qc_value is not None:\n",
    "        metadata['qc_temporal_expansion'] = int(qc_value)\n",
    "        metadata['composite_date_range'] = f\"±{qc_value} months from base\"\n",
    "    \n",
    "    # Set metadata\n",
    "    rgb_with_metadata = rgb_image.set(metadata)\n",
    "    \n",
    "    # Export\n",
    "    task = ee.batch.Export.image.toAsset(\n",
    "        image=rgb_with_metadata,\n",
    "        description=f\"Composite_RGB_{year}_{month:02d}\",\n",
    "        assetId=asset_id,\n",
    "        scale=10,\n",
    "        region=roi,\n",
    "        maxPixels=1e13\n",
    "    )\n",
    "    task.start()\n",
    "    logging.info(f\"Exporting RGB composite to {asset_id}...\")\n",
    "    \n",
    "def process_monthly_dswe(start_date, end_date, roi, \n",
    "                         mask_asset_folder, \n",
    "                         composite_asset_folder,\n",
    "                         qc_asset_folder,\n",
    "                         output_dir='./swir2_histograms_DN',\n",
    "                         min_swir2_dn=400,\n",
    "                         max_swir2_dn=1500,\n",
    "                         morpho_size_threshold=150,\n",
    "                         morpho_class_threshold=2,\n",
    "                         max_temporal_expansion=2,\n",
    "                         coverage_threshold=0.95,\n",
    "                         save_histograms=True):\n",
    "    \"\"\"\n",
    "    Generate and export enhanced DSWE products for each month with Test 6 and morphological filtering.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    start_date : datetime\n",
    "        Start date for processing\n",
    "    end_date : datetime\n",
    "        End date for processing\n",
    "    roi : ee.Geometry\n",
    "        Region of interest\n",
    "    mask_asset_folder : str\n",
    "        GEE asset folder for DSWE products\n",
    "    composite_asset_folder : str\n",
    "        GEE asset folder for RGB composites\n",
    "    qc_asset_folder : str\n",
    "        GEE asset folder for QC rasters\n",
    "    output_dir : str, optional (default='./swir2_histograms_DN')\n",
    "        Directory to save SWIR2 histogram plots\n",
    "    min_swir2_dn : float, optional (default=400)\n",
    "        Minimum SWIR2 threshold (DN)\n",
    "    max_swir2_dn : float, optional (default=1500)\n",
    "        Maximum SWIR2 threshold (DN)\n",
    "    morpho_size_threshold : int, optional (default=150)\n",
    "        Blob size threshold for morphological filter (pixels)\n",
    "    morpho_class_threshold : int, optional (default=2)\n",
    "        Max class threshold for morphological filter\n",
    "    max_temporal_expansion : int, optional (default=2)\n",
    "        Maximum temporal expansion for gap filling (±N months)\n",
    "    coverage_threshold : float, optional (default=0.95)\n",
    "        Minimum coverage threshold (0.0 to 1.0)\n",
    "    save_histograms : bool, optional (default=True)\n",
    "        Whether to save SWIR2 histogram plots\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create output directory for histograms\n",
    "    if save_histograms:\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        logging.info(f\"SWIR2 histograms will be saved to: {output_dir}\")\n",
    "    \n",
    "    current_date = start_date\n",
    "    \n",
    "    while current_date <= end_date:\n",
    "        year = current_date.year\n",
    "        month = current_date.month\n",
    "        \n",
    "        logging.info(f\"\\n{'='*60}\")\n",
    "        logging.info(f\"Processing {year}-{month:02d}\")\n",
    "        logging.info(f\"{'='*60}\")\n",
    "        \n",
    "        try:\n",
    "            # ================================================================\n",
    "            # Step 1: Create composite with gap filling\n",
    "            # ================================================================\n",
    "            logging.info(\"Step 1: Creating composite with gap filling...\")\n",
    "            \n",
    "            composite, qc_value, coverage = create_monthly_composite_with_gap_filling(\n",
    "                year=year,\n",
    "                month=month,\n",
    "                roi=roi,\n",
    "                max_expansion=max_temporal_expansion,\n",
    "                coverage_threshold=coverage_threshold\n",
    "            )\n",
    "            \n",
    "            # Check if composite was created\n",
    "            if composite is None:\n",
    "                logging.error(f\"  No data available for {year}-{month:02d}. Skipping.\")\n",
    "                current_date = (current_date.replace(day=28) + timedelta(days=4)).replace(day=1)\n",
    "                continue\n",
    "            \n",
    "            logging.info(f\"  ✓ Composite created successfully\")\n",
    "            logging.info(f\"    QC Value: {qc_value} (0=base month, 1=±1 month, 2=±2 months)\")\n",
    "            logging.info(f\"    Final Coverage: {coverage*100:.1f}%\")\n",
    "            \n",
    "            # Warning if coverage is still below threshold\n",
    "            if coverage < coverage_threshold:\n",
    "                logging.warning(f\"  ⚠ Coverage ({coverage*100:.1f}%) below threshold \"\n",
    "                              f\"({coverage_threshold*100:.0f}%) after {max_temporal_expansion} month expansion\")\n",
    "            \n",
    "            # ================================================================\n",
    "            # Step 2: Calculate dynamic SWIR2 threshold\n",
    "            # ================================================================\n",
    "            logging.info(\"Step 2: Calculating dynamic SWIR2 threshold...\")\n",
    "            \n",
    "            swir2_threshold = calculate_dynamic_swir2_threshold(\n",
    "                composite, \n",
    "                roi,\n",
    "                min_swir2=min_swir2_dn,\n",
    "                max_swir2=max_swir2_dn,\n",
    "                save_plot=save_histograms,\n",
    "                output_dir=output_dir,\n",
    "                year=year,\n",
    "                month=month\n",
    "            )\n",
    "            \n",
    "            logging.info(f\"  ✓ SWIR2 Threshold: {swir2_threshold:.0f} DN\")\n",
    "            \n",
    "            # ================================================================\n",
    "            # Step 3: Apply DSWE with Test 6\n",
    "            # ================================================================\n",
    "            logging.info(\"Step 3: Applying DSWE with Test 6...\")\n",
    "            \n",
    "            upgraded_dswe, original_dswe, threshold = Dswe_with_Test6(\n",
    "                composite,\n",
    "                roi,\n",
    "                min_swir2=min_swir2_dn,\n",
    "                max_swir2=max_swir2_dn,\n",
    "                save_plot=False,  # Already saved in Step 2\n",
    "                output_dir=output_dir,\n",
    "                year=year,\n",
    "                month=month\n",
    "            )\n",
    "            \n",
    "            logging.info(f\"  ✓ DSWE classification complete (with Test 6 enhancement)\")\n",
    "            \n",
    "            # ================================================================\n",
    "            # Step 4: Apply morphological filter with diagnostics\n",
    "            # ================================================================\n",
    "            logging.info(\"Step 4: Applying morphological filter...\")\n",
    "            \n",
    "            filtered_dswe, diagnostics = morphological_filter(\n",
    "                upgraded_dswe,\n",
    "                size_threshold=morpho_size_threshold,\n",
    "                max_class_threshold=morpho_class_threshold,\n",
    "                roi=roi,\n",
    "                return_diagnostics=True\n",
    "            )\n",
    "            \n",
    "            logging.info(f\"  ✓ Morphological filter applied\")\n",
    "            \n",
    "            # ================================================================\n",
    "            # Step 5: Log diagnostics\n",
    "            # ================================================================\n",
    "            logging.info(\"Step 5: Filter Diagnostics:\")\n",
    "            logging.info(f\"  Pixels removed: {diagnostics['pixels_removed']:,}\")\n",
    "            logging.info(f\"  Area removed: {diagnostics['area_removed_km2']:.2f} km²\")\n",
    "            logging.info(f\"  Percent water removed: {diagnostics['percent_water_removed']:.2f}%\")\n",
    "            logging.info(f\"  Class breakdown:\")\n",
    "            logging.info(f\"    Class 1 removed: {diagnostics['class_1_pixels_removed']:,} pixels\")\n",
    "            logging.info(f\"    Class 2 removed: {diagnostics['class_2_pixels_removed']:,} pixels\")\n",
    "            logging.info(f\"    Class 3 removed: {diagnostics['class_3_pixels_removed']:,} pixels (should be 0)\")\n",
    "            logging.info(f\"    Class 4 removed: {diagnostics['class_4_pixels_removed']:,} pixels (should be 0)\")\n",
    "            \n",
    "            # Sanity check: warn if high-confidence pixels were removed\n",
    "            if diagnostics['class_3_pixels_removed'] > 0 or diagnostics['class_4_pixels_removed'] > 0:\n",
    "                logging.warning(f\"  ⚠ High-confidence water pixels were removed! Check filter parameters.\")\n",
    "            \n",
    "            # ================================================================\n",
    "            # Step 6: Create QC raster\n",
    "            # ================================================================\n",
    "            logging.info(\"Step 6: Creating QC raster...\")\n",
    "            \n",
    "            qc_raster = ee.Image.constant(qc_value).clip(roi).rename('QC').toInt8()\n",
    "            \n",
    "            logging.info(f\"  ✓ QC raster created (value={qc_value})\")\n",
    "            \n",
    "            # ================================================================\n",
    "            # Step 7: Export all products\n",
    "            # ================================================================\n",
    "            logging.info(\"Step 7: Exporting products to GEE...\")\n",
    "            \n",
    "            # Export DSWE product\n",
    "            export_to_asset(\n",
    "                filtered_dswe, \n",
    "                year, \n",
    "                month, \n",
    "                mask_asset_folder, \n",
    "                roi,\n",
    "                swir2_threshold=swir2_threshold,\n",
    "                qc_value=qc_value,\n",
    "                morpho_diagnostics=diagnostics,\n",
    "                size_threshold=morpho_size_threshold,\n",
    "                max_class_threshold=morpho_class_threshold\n",
    "            )\n",
    "            \n",
    "            # Export QC raster\n",
    "            export_qc_raster(\n",
    "                qc_raster, \n",
    "                year, \n",
    "                month, \n",
    "                qc_asset_folder, \n",
    "                roi\n",
    "            )\n",
    "            \n",
    "            # Export RGB composite\n",
    "            export_composite_image(\n",
    "                composite, \n",
    "                year, \n",
    "                month, \n",
    "                composite_asset_folder, \n",
    "                roi,\n",
    "                qc_value=qc_value\n",
    "            )\n",
    "            \n",
    "            logging.info(f\"  ✓ All exports initiated successfully\")\n",
    "            logging.info(f\"✓ Processing complete for {year}-{month:02d}\\n\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            logging.error(f\"✗ Failed to process {year}-{month:02d}: {str(e)}\")\n",
    "            logging.exception(\"Full traceback:\")\n",
    "        \n",
    "        # Move to next month\n",
    "        current_date = (current_date.replace(day=28) + timedelta(days=4)).replace(day=1)\n",
    "    \n",
    "    logging.info(f\"\\n{'='*60}\")\n",
    "    logging.info(\"Processing complete for all months\")\n",
    "    logging.info(f\"{'='*60}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c5558a",
   "metadata": {},
   "source": [
    "## Input pathnames, parameter, and run "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dae1c76e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-03 10:55:47,124 - INFO - \n",
      "============================================================\n",
      "2025-12-03 10:55:47,125 - INFO - Processing 2024-08\n",
      "2025-12-03 10:55:47,127 - INFO - ============================================================\n",
      "2025-12-03 10:55:47,127 - INFO - Step 1: Creating composite with gap filling...\n",
      "2025-12-03 10:55:47,129 - INFO -   Attempting base month composite (2024-08)...\n",
      "2025-12-03 10:56:06,185 - INFO -   Base month coverage: 100.0%\n",
      "2025-12-03 10:56:06,187 - INFO -   ✓ Composite created successfully\n",
      "2025-12-03 10:56:06,189 - INFO -     QC Value: 0 (0=base month, 1=±1 month, 2=±2 months)\n",
      "2025-12-03 10:56:06,193 - INFO -     Final Coverage: 100.0%\n",
      "2025-12-03 10:56:06,194 - INFO - Step 2: Calculating dynamic SWIR2 threshold...\n",
      "2025-12-03 10:59:23,765 - INFO -   ✓ SWIR2 Threshold: 1500 DN\n",
      "2025-12-03 10:59:23,767 - INFO - Step 3: Applying DSWE with Test 6...\n",
      "2025-12-03 10:59:24,327 - INFO -   ✓ DSWE classification complete (with Test 6 enhancement)\n",
      "2025-12-03 10:59:24,329 - INFO - Step 4: Applying morphological filter...\n",
      "2025-12-03 11:07:21,969 - WARNING - Could not calculate diagnostics: Computation timed out.\n",
      "2025-12-03 11:07:21,972 - INFO -   ✓ Morphological filter applied\n",
      "2025-12-03 11:07:21,975 - INFO - Step 5: Filter Diagnostics:\n",
      "2025-12-03 11:07:21,977 - INFO -   Pixels removed: 0\n",
      "2025-12-03 11:07:21,979 - INFO -   Area removed: 0.00 km²\n",
      "2025-12-03 11:07:21,983 - INFO -   Percent water removed: 0.00%\n",
      "2025-12-03 11:07:21,985 - INFO -   Class breakdown:\n",
      "2025-12-03 11:07:21,988 - INFO -     Class 1 removed: 0 pixels\n",
      "2025-12-03 11:07:21,990 - INFO -     Class 2 removed: 0 pixels\n",
      "2025-12-03 11:07:21,992 - INFO -     Class 3 removed: 0 pixels (should be 0)\n",
      "2025-12-03 11:07:21,995 - INFO -     Class 4 removed: 0 pixels (should be 0)\n",
      "2025-12-03 11:07:21,997 - INFO - Step 6: Creating QC raster...\n",
      "2025-12-03 11:07:22,001 - INFO -   ✓ QC raster created (value=0)\n",
      "2025-12-03 11:07:22,004 - INFO - Step 7: Exporting products to GEE...\n",
      "2025-12-03 11:07:22,468 - INFO - Exporting projects/ee-okavango/assets/water_masks/monthly_DSWE_Sent2_10m_v3/DSWE_Products/DSWE_2024_08...\n",
      "2025-12-03 11:07:22,871 - INFO - Exporting projects/ee-okavango/assets/water_masks/monthly_DSWE_Sent2_10m_v3/QC_Rastersxx/QC_2024_08...\n",
      "2025-12-03 11:07:23,301 - INFO - Exporting RGB composite to projects/ee-okavango/assets/water_masks/monthly_DSWE_Sent2_10m_v3/Source_S2_Compositesxx/Composite_2024_08...\n",
      "2025-12-03 11:07:23,303 - INFO -   ✓ All exports initiated successfully\n",
      "2025-12-03 11:07:23,304 - INFO - ✓ Processing complete for 2024-08\n",
      "\n",
      "2025-12-03 11:07:23,307 - INFO - \n",
      "============================================================\n",
      "2025-12-03 11:07:23,309 - INFO - Processing complete for all months\n",
      "2025-12-03 11:07:23,312 - INFO - ============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "start_date = datetime(2024, 8, 1)\n",
    "end_date = datetime(2024, 8, 31)\n",
    "study_area_path = r\"C:\\Users\\huckr\\Desktop\\UCSB\\Okavango\\Data\\StudyAreas\\Delta_UCB\\Delta_UCB_WGS84.shp\"\n",
    "\n",
    "# Asset folders (create these in GEE first!)\n",
    "mask_asset_folder = \"projects/ee-okavango/assets/water_masks/monthly_DSWE_Sent2_10m_v3/DSWE_Products\"\n",
    "composite_asset_folder = \"projects/ee-okavango/assets/water_masks/monthly_DSWE_Sent2_10m_v3/Source_S2_Compositesxx\"\n",
    "qc_asset_folder = \"projects/ee-okavango/assets/water_masks/monthly_DSWE_Sent2_10m_v3/QC_Rastersxx\"\n",
    "\n",
    "# Load ROI\n",
    "roi = load_roi(study_area_path)\n",
    "\n",
    "# Run processing\n",
    "process_monthly_dswe(\n",
    "    start_date=start_date,\n",
    "    end_date=end_date,\n",
    "    roi=roi,\n",
    "    mask_asset_folder=mask_asset_folder,\n",
    "    composite_asset_folder=composite_asset_folder,\n",
    "    qc_asset_folder=qc_asset_folder,\n",
    "    output_dir=r'D:\\Okavango\\Data\\Water_Masks\\Sentinel2\\S2_SWIR2_histograms',\n",
    "    min_swir2_dn=400,\n",
    "    max_swir2_dn=1500,\n",
    "    morpho_size_threshold=150,\n",
    "    morpho_class_threshold=2,\n",
    "    max_temporal_expansion=2,\n",
    "    coverage_threshold=0.95,\n",
    "    save_histograms=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7dec4f4",
   "metadata": {},
   "source": [
    "## Monitor GEE tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f28077af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: Composite_RGB_2024_08, Status: FAILED\n",
      "Task: QC_2024_08, Status: FAILED\n",
      "Task: DSWE_2024_08, Status: RUNNING\n",
      "Task: Composite_RGB_2024_08, Status: FAILED\n",
      "Task: QC_2024_08, Status: FAILED\n",
      "Task: DSWE_2024_08, Status: CANCELLED\n",
      "Task: Composite_RGB_2024_08, Status: FAILED\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Print task statuses\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m task_list:\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTask: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtask.status()[\u001b[33m'\u001b[39m\u001b[33mdescription\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, Status: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtask.status()[\u001b[33m'\u001b[39m\u001b[33mstate\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\Lib\\site-packages\\ee\\batch.py:176\u001b[39m, in \u001b[36mTask.status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    163\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Fetches the current status of the task.\u001b[39;00m\n\u001b[32m    164\u001b[39m \n\u001b[32m    165\u001b[39m \u001b[33;03mReturns:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    173\u001b[39m \u001b[33;03m  May also include other fields.\u001b[39;00m\n\u001b[32m    174\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    175\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.operation_name:\n\u001b[32m--> \u001b[39m\u001b[32m176\u001b[39m   operation = data.getOperation(\u001b[38;5;28mself\u001b[39m.operation_name)\n\u001b[32m    177\u001b[39m   result = _cloud_api_utils.convert_operation_to_task(operation)\n\u001b[32m    178\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m result[\u001b[33m'\u001b[39m\u001b[33mstate\u001b[39m\u001b[33m'\u001b[39m] == \u001b[33m'\u001b[39m\u001b[33mUNKNOWN\u001b[39m\u001b[33m'\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\Lib\\site-packages\\ee\\data.py:1726\u001b[39m, in \u001b[36mgetOperation\u001b[39m\u001b[34m(operation_name)\u001b[39m\n\u001b[32m   1716\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgetOperation\u001b[39m(operation_name: \u001b[38;5;28mstr\u001b[39m) -> Any:\n\u001b[32m   1717\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Retrieves the status of a long-running operation.\u001b[39;00m\n\u001b[32m   1718\u001b[39m \n\u001b[32m   1719\u001b[39m \u001b[33;03m  Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1724\u001b[39m \u001b[33;03m    An Operation status dictionary for the requested operation.\u001b[39;00m\n\u001b[32m   1725\u001b[39m \u001b[33;03m  \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1726\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m _execute_cloud_call(\n\u001b[32m   1727\u001b[39m       _get_cloud_projects().operations().get(name=operation_name)\n\u001b[32m   1728\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\Lib\\site-packages\\ee\\data.py:408\u001b[39m, in \u001b[36m_execute_cloud_call\u001b[39m\u001b[34m(call, num_retries)\u001b[39m\n\u001b[32m    406\u001b[39m num_retries = _max_retries \u001b[38;5;28;01mif\u001b[39;00m num_retries \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m num_retries\n\u001b[32m    407\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m408\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m call.execute(num_retries=num_retries)\n\u001b[32m    409\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m googleapiclient.errors.HttpError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    410\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m _translate_cloud_exception(e)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\Lib\\site-packages\\googleapiclient\\_helpers.py:130\u001b[39m, in \u001b[36mpositional.<locals>.positional_decorator.<locals>.positional_wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    128\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m positional_parameters_enforcement == POSITIONAL_WARNING:\n\u001b[32m    129\u001b[39m         logger.warning(message)\n\u001b[32m--> \u001b[39m\u001b[32m130\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\Lib\\site-packages\\googleapiclient\\http.py:923\u001b[39m, in \u001b[36mHttpRequest.execute\u001b[39m\u001b[34m(self, http, num_retries)\u001b[39m\n\u001b[32m    920\u001b[39m     \u001b[38;5;28mself\u001b[39m.headers[\u001b[33m\"\u001b[39m\u001b[33mcontent-length\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.body))\n\u001b[32m    922\u001b[39m \u001b[38;5;66;03m# Handle retries for server-side errors.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m923\u001b[39m resp, content = _retry_request(\n\u001b[32m    924\u001b[39m     http,\n\u001b[32m    925\u001b[39m     num_retries,\n\u001b[32m    926\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mrequest\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    927\u001b[39m     \u001b[38;5;28mself\u001b[39m._sleep,\n\u001b[32m    928\u001b[39m     \u001b[38;5;28mself\u001b[39m._rand,\n\u001b[32m    929\u001b[39m     \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m.uri),\n\u001b[32m    930\u001b[39m     method=\u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m.method),\n\u001b[32m    931\u001b[39m     body=\u001b[38;5;28mself\u001b[39m.body,\n\u001b[32m    932\u001b[39m     headers=\u001b[38;5;28mself\u001b[39m.headers,\n\u001b[32m    933\u001b[39m )\n\u001b[32m    935\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.response_callbacks:\n\u001b[32m    936\u001b[39m     callback(resp)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\Lib\\site-packages\\googleapiclient\\http.py:191\u001b[39m, in \u001b[36m_retry_request\u001b[39m\u001b[34m(http, num_retries, req_type, sleep, rand, uri, method, *args, **kwargs)\u001b[39m\n\u001b[32m    189\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    190\u001b[39m     exception = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m191\u001b[39m     resp, content = http.request(uri, method, *args, **kwargs)\n\u001b[32m    192\u001b[39m \u001b[38;5;66;03m# Retry on SSL errors and socket timeout errors.\u001b[39;00m\n\u001b[32m    193\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m _ssl_SSLError \u001b[38;5;28;01mas\u001b[39;00m ssl_error:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\Lib\\site-packages\\google_auth_httplib2.py:218\u001b[39m, in \u001b[36mAuthorizedHttp.request\u001b[39m\u001b[34m(self, uri, method, body, headers, redirections, connection_type, **kwargs)\u001b[39m\n\u001b[32m    215\u001b[39m     body_stream_position = body.tell()\n\u001b[32m    217\u001b[39m \u001b[38;5;66;03m# Make the request.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m response, content = \u001b[38;5;28mself\u001b[39m.http.request(\n\u001b[32m    219\u001b[39m     uri,\n\u001b[32m    220\u001b[39m     method,\n\u001b[32m    221\u001b[39m     body=body,\n\u001b[32m    222\u001b[39m     headers=request_headers,\n\u001b[32m    223\u001b[39m     redirections=redirections,\n\u001b[32m    224\u001b[39m     connection_type=connection_type,\n\u001b[32m    225\u001b[39m     **kwargs\n\u001b[32m    226\u001b[39m )\n\u001b[32m    228\u001b[39m \u001b[38;5;66;03m# If the response indicated that the credentials needed to be\u001b[39;00m\n\u001b[32m    229\u001b[39m \u001b[38;5;66;03m# refreshed, then refresh the credentials and re-attempt the\u001b[39;00m\n\u001b[32m    230\u001b[39m \u001b[38;5;66;03m# request.\u001b[39;00m\n\u001b[32m    231\u001b[39m \u001b[38;5;66;03m# A stored token may expire between the time it is retrieved and\u001b[39;00m\n\u001b[32m    232\u001b[39m \u001b[38;5;66;03m# the time the request is made, so we may need to try twice.\u001b[39;00m\n\u001b[32m    233\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    234\u001b[39m     response.status \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._refresh_status_codes\n\u001b[32m    235\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m _credential_refresh_attempt < \u001b[38;5;28mself\u001b[39m._max_refresh_attempts\n\u001b[32m    236\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\Lib\\site-packages\\ee\\_cloud_api_utils.py:70\u001b[39m, in \u001b[36m_Http.request\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m     63\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m redirections  \u001b[38;5;66;03m# Ignored\u001b[39;00m\n\u001b[32m     65\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     66\u001b[39m   \u001b[38;5;66;03m# googleapiclient is expecting an httplib2 object, and doesn't include\u001b[39;00m\n\u001b[32m     67\u001b[39m   \u001b[38;5;66;03m# requests error in the list of transient errors. Therefore, transient\u001b[39;00m\n\u001b[32m     68\u001b[39m   \u001b[38;5;66;03m# requests errors should be converted to kinds that googleapiclient\u001b[39;00m\n\u001b[32m     69\u001b[39m   \u001b[38;5;66;03m# consider transient.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m70\u001b[39m   response = \u001b[38;5;28mself\u001b[39m._session.request(\n\u001b[32m     71\u001b[39m       method, uri, data=body, headers=headers, timeout=\u001b[38;5;28mself\u001b[39m._timeout\n\u001b[32m     72\u001b[39m   )\n\u001b[32m     73\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m requests.exceptions.ConnectionError \u001b[38;5;28;01mas\u001b[39;00m connection_error:\n\u001b[32m     74\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(connection_error) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mconnection_error\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\Lib\\site-packages\\requests\\sessions.py:589\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    584\u001b[39m send_kwargs = {\n\u001b[32m    585\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m: timeout,\n\u001b[32m    586\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m: allow_redirects,\n\u001b[32m    587\u001b[39m }\n\u001b[32m    588\u001b[39m send_kwargs.update(settings)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28mself\u001b[39m.send(prep, **send_kwargs)\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\Lib\\site-packages\\requests\\sessions.py:703\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    700\u001b[39m start = preferred_clock()\n\u001b[32m    702\u001b[39m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m703\u001b[39m r = adapter.send(request, **kwargs)\n\u001b[32m    705\u001b[39m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[32m    706\u001b[39m elapsed = preferred_clock() - start\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\Lib\\site-packages\\requests\\adapters.py:667\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    664\u001b[39m     timeout = TimeoutSauce(connect=timeout, read=timeout)\n\u001b[32m    666\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m667\u001b[39m     resp = conn.urlopen(\n\u001b[32m    668\u001b[39m         method=request.method,\n\u001b[32m    669\u001b[39m         url=url,\n\u001b[32m    670\u001b[39m         body=request.body,\n\u001b[32m    671\u001b[39m         headers=request.headers,\n\u001b[32m    672\u001b[39m         redirect=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    673\u001b[39m         assert_same_host=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    674\u001b[39m         preload_content=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    675\u001b[39m         decode_content=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    676\u001b[39m         retries=\u001b[38;5;28mself\u001b[39m.max_retries,\n\u001b[32m    677\u001b[39m         timeout=timeout,\n\u001b[32m    678\u001b[39m         chunked=chunked,\n\u001b[32m    679\u001b[39m     )\n\u001b[32m    681\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    682\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request=request)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:787\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    784\u001b[39m response_conn = conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    786\u001b[39m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m response = \u001b[38;5;28mself\u001b[39m._make_request(\n\u001b[32m    788\u001b[39m     conn,\n\u001b[32m    789\u001b[39m     method,\n\u001b[32m    790\u001b[39m     url,\n\u001b[32m    791\u001b[39m     timeout=timeout_obj,\n\u001b[32m    792\u001b[39m     body=body,\n\u001b[32m    793\u001b[39m     headers=headers,\n\u001b[32m    794\u001b[39m     chunked=chunked,\n\u001b[32m    795\u001b[39m     retries=retries,\n\u001b[32m    796\u001b[39m     response_conn=response_conn,\n\u001b[32m    797\u001b[39m     preload_content=preload_content,\n\u001b[32m    798\u001b[39m     decode_content=decode_content,\n\u001b[32m    799\u001b[39m     **response_kw,\n\u001b[32m    800\u001b[39m )\n\u001b[32m    802\u001b[39m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[32m    803\u001b[39m clean_exit = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:534\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    532\u001b[39m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[32m    533\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m534\u001b[39m     response = conn.getresponse()\n\u001b[32m    535\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    536\u001b[39m     \u001b[38;5;28mself\u001b[39m._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\Lib\\site-packages\\urllib3\\connection.py:516\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    513\u001b[39m _shutdown = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.sock, \u001b[33m\"\u001b[39m\u001b[33mshutdown\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    515\u001b[39m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m516\u001b[39m httplib_response = \u001b[38;5;28msuper\u001b[39m().getresponse()\n\u001b[32m    518\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    519\u001b[39m     assert_header_parsing(httplib_response.msg)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\Lib\\http\\client.py:1378\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1376\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1377\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1378\u001b[39m         response.begin()\n\u001b[32m   1379\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[32m   1380\u001b[39m         \u001b[38;5;28mself\u001b[39m.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\Lib\\http\\client.py:318\u001b[39m, in \u001b[36mHTTPResponse.begin\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    316\u001b[39m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[32m    317\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m318\u001b[39m     version, status, reason = \u001b[38;5;28mself\u001b[39m._read_status()\n\u001b[32m    319\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m status != CONTINUE:\n\u001b[32m    320\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\Lib\\http\\client.py:279\u001b[39m, in \u001b[36mHTTPResponse._read_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    278\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m279\u001b[39m     line = \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m.fp.readline(_MAXLINE + \u001b[32m1\u001b[39m), \u001b[33m\"\u001b[39m\u001b[33miso-8859-1\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    280\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) > _MAXLINE:\n\u001b[32m    281\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[33m\"\u001b[39m\u001b[33mstatus line\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\Lib\\socket.py:706\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    704\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    705\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m706\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sock.recv_into(b)\n\u001b[32m    707\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[32m    708\u001b[39m         \u001b[38;5;28mself\u001b[39m._timeout_occurred = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\Lib\\ssl.py:1311\u001b[39m, in \u001b[36mSSLSocket.recv_into\u001b[39m\u001b[34m(self, buffer, nbytes, flags)\u001b[39m\n\u001b[32m   1307\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1308\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1309\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1310\u001b[39m           \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1311\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.read(nbytes, buffer)\n\u001b[32m   1312\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1313\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv_into(buffer, nbytes, flags)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\Lib\\ssl.py:1167\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1165\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1166\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1167\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[32m   1168\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1169\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Get list of all running GEE tasks\n",
    "task_list = ee.batch.Task.list()\n",
    "\n",
    "# Print task statuses\n",
    "\n",
    "for task in task_list:\n",
    "    print(f\"Task: {task.status()['description']}, Status: {task.status()['state']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192299fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
